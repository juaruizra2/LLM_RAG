# Sistema RAG para RecomendaciÃ³n de PelÃ­culas

Un sistema completo de Retrieval-Augmented Generation (RAG) que utiliza embeddings de texto para responder preguntas sobre pelÃ­culas basÃ¡ndose en una base de conocimientos de sinopsis cinematogrÃ¡ficas. Incluye APIs REST para integraciÃ³n web.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema RAG completo que:

- **Preprocesa** texto de sinopsis de pelÃ­culas con pipeline optimizado
- **Genera embeddings** usando mÃºltiples modelos (FlagEmbedding, SentenceTransformer, OpenAI)
- **Indexa** los embeddings en archivos Parquet para bÃºsqueda eficiente
- **Responde preguntas** combinando bÃºsqueda por similitud y generaciÃ³n de texto con GPT-4
- **Proporciona APIs REST** para integraciÃ³n web y servicios

## ğŸ—ï¸ Arquitectura del Proyecto

```
project_1/
â”œâ”€â”€ config.py                 # ConfiguraciÃ³n de modelos y parÃ¡metros
â”œâ”€â”€ preprocessing.py          # Pipeline de preprocesamiento de texto
â”œâ”€â”€ embeddings_factory.py     # Factory para diferentes tipos de embeddings
â”œâ”€â”€ embeddings_indexing.py    # Script para crear la base de conocimientos
â”œâ”€â”€ rag.py                   # Sistema RAG principal
â”œâ”€â”€ flask_api.py             # API Flask completa con endpoints
â”œâ”€â”€ api.py                   # API Flask simplificada
â”œâ”€â”€ rag_model.pickle         # Modelo RAG serializado (143MB)
â”œâ”€â”€ data/                    # Datos y embeddings preprocesados
â”‚   â”œâ”€â”€ movies-dataset.csv
â”‚   â”œâ”€â”€ movies-dataset.parquet
â”‚   â”œâ”€â”€ movies-dataset-embeddings-flag.parquet
â”‚   â”œâ”€â”€ movies-dataset-embeddings-sentence_transformer.parquet
â”‚   â””â”€â”€ movies-dataset-embeddings-openai.parquet
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â””â”€â”€ README.md               # DocumentaciÃ³n
```
<img width="1080" height="1512" alt="image" src="https://github.com/user-attachments/assets/905da908-3e42-4aca-9fbc-a557b056162c" />



## ğŸš€ InstalaciÃ³n

1. **Clonar el repositorio:**
   ```bash
   git clone <repository-url>
   cd project_1
   ```

2. **Crear entorno virtual:**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # En Windows: .venv\Scripts\activate
   ```

3. **Instalar dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ“Š Datos

El sistema utiliza un dataset de pelÃ­culas que incluye:
- **movies-dataset.csv**: Dataset original con informaciÃ³n de pelÃ­culas (5.9MB)
- **movies-dataset.parquet**: VersiÃ³n optimizada en formato Parquet (3.6MB)
- **Archivos de embeddings**: Base de conocimientos con embeddings precalculados
  - FlagEmbedding: 69KB (373 lÃ­neas)
  - SentenceTransformer: 11MB
  - OpenAI: 151KB (723 lÃ­neas)

### Formatos de Embeddings Soportados:
- **FlagEmbedding**: BAAI/bge-m3 (alto rendimiento, menor tamaÃ±o)
- **SentenceTransformer**: BAAI/bge-small-en-v1.5 (equilibrio rendimiento/velocidad)
- **OpenAI**: text-embedding-3-small (requiere API key)

## ğŸ”§ Uso

### 1. Crear Base de Conocimientos

Para generar embeddings y crear la base de conocimientos:

```bash
python embeddings_indexing.py
```

Esto crearÃ¡ archivos Parquet con embeddings para cada tipo de modelo configurado.

### 2. Ejecutar Sistema RAG

```bash
python rag.py
```

El sistema cargarÃ¡ automÃ¡ticamente:
- La base de conocimientos segÃºn la configuraciÃ³n en `config.py`
- El preprocesador de texto
- El modelo de embeddings especificado
- GuardarÃ¡ el modelo serializado en `rag_model.pickle`

### 3. API REST

#### API Completa (flask_api.py)
```bash
python flask_api.py
```

**Endpoints disponibles:**
- `GET /` - InformaciÃ³n de la API
- `GET /health` - Verificar estado de la API
- `GET /query?question=<pregunta>` - Consulta simple
- `POST /query` - Consulta con JSON

**Ejemplo de uso:**
```bash
# GET request
curl "http://localhost:5000/query?question=What is the name of the movie where humans and AIs coexist?"

# POST request
curl -X POST http://localhost:5000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "What is the name of the movie where humans and AIs coexist?"}'
```

#### API Simplificada (api.py)
```bash
python api.py
```

**Endpoints:**
- `GET /health` - Estado de la API
- `GET /query` - Consulta (requiere JSON con campo 'question')

### 4. ConfiguraciÃ³n

Edita `config.py` para personalizar:

```python
# Tipo de embeddings a usar
embedding_to_use = "sentence_transformer"

# Umbral de similitud para filtrar resultados
similarity_threshold = 0.55

# Modelos disponibles
embedding_models = {
    "flag": {"model": "BAAI/bge-m3"},
    "sentence_transformer": {"model": "BAAI/bge-small-en-v1.5"},
    "openai": {"model": "text-embedding-3-small"}
}
```

## ğŸ§  Componentes Principales

### TextPreprocessor
Pipeline de preprocesamiento optimizado que incluye:
- ConversiÃ³n a minÃºsculas
- EliminaciÃ³n de acentos y caracteres especiales
- Limpieza de secuencias de escape
- EliminaciÃ³n de emojis
- EliminaciÃ³n de puntuaciÃ³n
- NormalizaciÃ³n de espacios
- Procesamiento por lotes

### EmbeddingFactory
Factory pattern que soporta mÃºltiples tipos de embeddings:
- **FlagEmbeddingGenerator**: Para modelos BGE-M3 (optimizado con FP16)
- **SentenceTransformerGenerator**: Para modelos SentenceTransformer
- **OpenAIEmbeddingGenerator**: Para embeddings de OpenAI API
- **GeneraciÃ³n por lotes**: Para procesamiento eficiente de mÃºltiples textos

### RAG System
Sistema principal que:
1. Preprocesa la consulta del usuario
2. Genera embeddings para la consulta
3. Calcula similitud coseno con la base de conocimientos
4. Transforma distancias a similitud (1 - distancia)
5. Filtra por umbral de similitud configurable
6. Genera contexto relevante con URLs de imÃ¡genes
7. Usa GPT-4 para generar respuesta final
8. Serializa el modelo para uso posterior

### APIs Flask
- **flask_api.py**: API completa con manejo de errores, validaciÃ³n y documentaciÃ³n
- **api.py**: API simplificada para casos de uso bÃ¡sicos
- **Endpoints de salud**: Para monitoreo y verificaciÃ³n de estado
- **Manejo de errores**: Respuestas HTTP apropiadas con cÃ³digos de estado

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Cambiar Modelo de Embeddings

```python
# En config.py
embedding_to_use = "flag"  # o "sentence_transformer" o "openai"
```

### Ajustar Umbral de Similitud

```python
# En config.py
similarity_threshold = 0.80  # MÃ¡s estricto (actual: 0.55)
```

### Personalizar Prompt

Modifica la variable `prompt` en `config.py` para cambiar el comportamiento del sistema RAG.

### ConfiguraciÃ³n de OpenAI

El sistema incluye una API key de OpenAI configurada para GPT-4. Para usar tu propia key:

```python
# En rag.py, lÃ­nea 58
os.environ["OPENAI_API_KEY"] = "tu-api-key-aqui"
```

## ğŸ” Ejemplo de Uso

### Uso Directo del Sistema RAG

```python
from rag import RAG
from preprocessing import TextPreprocessor
import pandas as pd

# Cargar base de conocimientos
knowledge_base = pd.read_parquet("data/movies-dataset-embeddings-sentence_transformer.parquet")

# Inicializar sistema
preprocessor = TextPreprocessor()
rag = RAG(knowledge_base, preprocessor, embedding_type='sentence_transformer')

# Hacer consulta
question = "The film begins in a diner where Peter Parker"
response, context = rag.query(question)

print(f"Pregunta: {question}")
print(f"Respuesta: {response}")
print(f"Contexto: {context}")
```

### Uso con Modelo Serializado

```python
import pickle

# Cargar modelo pre-entrenado
with open('rag_model.pickle', 'rb') as f:
    rag = pickle.load(f)

# Hacer consulta
response, context = rag.query("What is the movie about?")
print(response)
```

## ğŸ“ˆ Rendimiento y CaracterÃ­sticas

### Modelos de Embeddings
- **FlagEmbedding**: Mayor precisiÃ³n, menor tamaÃ±o de archivo (69KB)
- **SentenceTransformer**: Equilibrio entre velocidad y precisiÃ³n (11MB)
- **OpenAI**: Requiere conexiÃ³n a internet, costo por uso (151KB)

### Optimizaciones
- **FP16**: Uso de precisiÃ³n media para acelerar inferencia
- **Parquet**: Formato optimizado para almacenamiento y lectura
- **SerializaciÃ³n**: Modelo guardado en pickle para carga rÃ¡pida
- **Procesamiento por lotes**: Para generaciÃ³n eficiente de embeddings

### APIs
- **Flask**: Framework web ligero y rÃ¡pido
- **JSON**: Formato de intercambio de datos
- **CORS**: Configurado para integraciÃ³n web
- **Health checks**: Para monitoreo de servicios

## ğŸ› ï¸ Requisitos del Sistema

### Dependencias Principales
- Python 3.8+
- pandas>=2.0.0
- numpy>=1.24.0
- scipy>=1.10.0
- sentence-transformers>=2.2.0
- FlagEmbedding>=1.2.0
- openai>=1.0.0
- flask>=2.3.0

### Requisitos de Hardware
- 8GB+ RAM (recomendado para modelos grandes)
- ConexiÃ³n a internet (para descargar modelos y usar OpenAI)
- 500MB+ espacio en disco (para modelos y embeddings)

### Dependencias Opcionales
- torch>=2.0.0 (para mejor rendimiento)
- transformers>=4.30.0
- pytest>=7.0.0 (para testing)
- black>=23.0.0 (para formateo de cÃ³digo)

## ğŸ”§ Desarrollo

### Estructura de CÃ³digo
- **PatrÃ³n Factory**: Para generaciÃ³n de embeddings
- **PatrÃ³n Strategy**: Para diferentes tipos de preprocesamiento
- **SeparaciÃ³n de responsabilidades**: Cada componente tiene una funciÃ³n especÃ­fica
- **ConfiguraciÃ³n centralizada**: Todos los parÃ¡metros en `config.py`

### Testing
```bash
# Instalar dependencias de desarrollo
pip install pytest black flake8

# Ejecutar tests
pytest

# Formatear cÃ³digo
black .

# Linting
flake8
```

## ğŸ“ Notas de ImplementaciÃ³n

- El sistema utiliza **similitud coseno** para calcular la relevancia
- Las **distancias se transforman** a similitud (1 - distancia) para facilitar interpretaciÃ³n
- El **umbral de similitud** es configurable (actual: 0.55)
- Se **filtran los top 2 resultados** mÃ¡s relevantes para generar contexto
- El **prompt incluye URLs de imÃ¡genes** cuando estÃ¡n disponibles
- Las **respuestas se generan en inglÃ©s** segÃºn la configuraciÃ³n

## ğŸš€ PrÃ³ximos Pasos

- [ ] Implementar cache de embeddings para consultas repetidas
- [ ] AÃ±adir autenticaciÃ³n a las APIs
- [ ] Implementar rate limiting
- [ ] AÃ±adir mÃ©tricas de rendimiento
- [ ] Crear interfaz web
- [ ] Implementar bÃºsqueda por filtros adicionales
- [ ] AÃ±adir soporte para mÃºltiples idiomas

